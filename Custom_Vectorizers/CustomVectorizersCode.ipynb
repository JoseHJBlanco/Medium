{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Custom Vectorizers<a class=\"tocSkip\" >\n",
    "---\n",
    "This notebook contains a series of code snippets used to create and demonstrate custom vectorizers.\n",
    "\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Standard-vectorizer\" data-toc-modified-id=\"Standard-vectorizer-0.0.1\">Standard vectorizer</a></span></li><li><span><a href=\"#Hand-made-vectorizer\" data-toc-modified-id=\"Hand-made-vectorizer-0.0.2\">Hand-made vectorizer</a></span></li><li><span><a href=\"#Customized-tokenizer-and-preprocessor\" data-toc-modified-id=\"Customized-tokenizer-and-preprocessor-0.0.3\">Customized tokenizer and preprocessor</a></span></li><li><span><a href=\"#Custom-analyzer\" data-toc-modified-id=\"Custom-analyzer-0.0.4\">Custom analyzer</a></span></li><li><span><a href=\"#Modified-vectorizer-class\" data-toc-modified-id=\"Modified-vectorizer-class-0.0.5\">Modified vectorizer class</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard vectorizer\n",
    "A run-of-the-mill vectorizer, nothing special about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jumps</th>\n",
       "      <th>The</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Jumps  The  brown  dog  fox  lazy  over  quick  the\n",
       "Doc0      0    1      1    0    1     0     0      1    0\n",
       "Doc1      1    0      0    1    0     1     1      0    1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas and sklearn's CountVectorizer class\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# print create a dataframe from a word matrix\n",
    "def wm2df(wm, feat_names):\n",
    "    doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(wm)]\n",
    "    df = pd.DataFrame(data=wm.toarray(), index=doc_names,\n",
    "                      columns=feat_names)\n",
    "    return(df)\n",
    "# set of documents\n",
    "corpora = ['The quick brown fox.','Jumps over the lazy dog!']\n",
    "# instantiate the vectorizer object\n",
    "cvec = CountVectorizer(lowercase=False)\n",
    "# convert the documents into a document-term matrix\n",
    "wm = cvec.fit_transform(corpora)\n",
    "# retrieve the terms found in the corpora\n",
    "tokens = cvec.get_feature_names()\n",
    "# create a dataframe from the matrix\n",
    "wm2df(wm, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-made vectorizer\n",
    "\n",
    "This functions together, when used together, work like a simplified version of sklearn's CountVectorizer. Its purpose is to ilustrate the different step necessary to make a vectorizer work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jumps</th>\n",
       "      <th>The</th>\n",
       "      <th>dog</th>\n",
       "      <th>quick</th>\n",
       "      <th>brown</th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>over</th>\n",
       "      <th>lazy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Jumps  The  dog  quick  brown  fox  the  over  lazy\n",
       "Doc0      0    1    0      1      1    1    0     0     0\n",
       "Doc1      1    0    1      0      0    0    1     1     1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# necessary imports\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def tokenize(corpus):\n",
    "    # create a pattern to extract words\n",
    "    pattern = re.compile(r'\\b\\w\\w+\\b')\n",
    "    return(re.findall(pattern, corpus))\n",
    "\n",
    "def set_weights(tokens):\n",
    "    # create a dictionary to hold the tokens and their weights\n",
    "    token_counts = defaultdict(int)\n",
    "    # iterate over the tokens increasing their weights by 1\n",
    "    for token in tokens:\n",
    "        token_counts[token] += 1\n",
    "    return(token_counts)\n",
    "\n",
    "def simple_vectorizer(corpora):\n",
    "    # create lists to hold the feature names, doc_counts and\n",
    "    # matrix_rows\n",
    "    feat_names = []\n",
    "    doc_counts = []\n",
    "    matrix_seed = []\n",
    "    \n",
    "    #iterate over the corpora and \n",
    "    for corpus in corpora:\n",
    "        # tokenize docs\n",
    "        tokens = tokenize(corpus)\n",
    "        # assign the weights\n",
    "        doc_count = set_weights(tokens)\n",
    "        # add the feat names and vectorized docs to the matrix\n",
    "        doc_counts.append(doc_count)\n",
    "        feat_names.extend(doc_count.keys())\n",
    "    \n",
    "    # create a list of unique feat names\n",
    "    unique_feat_names = list(set(feat_names))\n",
    "    \n",
    "    # assemble fill missing tokens with zeros\n",
    "    for doc_count in doc_counts:\n",
    "        matrix_row = [doc_count.get(feat_name, 0)\\\n",
    "                      for feat_name in unique_feat_names]\n",
    "        matrix_seed.append(matrix_row)\n",
    "        \n",
    "    # create a sparse matrix\n",
    "    matrix = csr_matrix(matrix_seed)\n",
    "    return(csr_matrix(matrix_seed), unique_feat_names)\n",
    "\n",
    "wm, tokens = simple_vectorizer(corpora)\n",
    "wm2df(wm, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized tokenizer and preprocessor\n",
    "\n",
    "Vectorizer customized by passing user defined callables as tokenizer and preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jump</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      !  .  brown  dog  fox  jump  lazy  over  quick  the\n",
       "Doc0  0  1      1    0    1     0     0     0      1    1\n",
       "Doc1  1  0      0    1    0     1     1     1      0    1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from html import unescape\n",
    "\n",
    "# create a spaCy tokenizer\n",
    "spacy.load('en')\n",
    "lemmatizer = spacy.lang.en.English()\n",
    "\n",
    "# remove html entities from docs and\n",
    "# set everything to lower case\n",
    "def my_preprocessor(doc):\n",
    "    return(unescape(doc).lower())\n",
    "\n",
    "# tokenize the doc and lemmatize its tokens\n",
    "def my_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens])\n",
    "\n",
    "corpora = [\n",
    "    'The quick brown fox&#x0002E;',\n",
    "    'jumped over the lazy dog&#x00021;'\n",
    "]\n",
    "\n",
    "custom_vec = CountVectorizer(preprocessor=my_preprocessor, tokenizer=my_tokenizer)\n",
    "cwm = custom_vec.fit_transform(corpora)\n",
    "tokens = custom_vec.get_feature_names()\n",
    "wm2df(cwm, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>brown fox</th>\n",
       "      <th>dog</th>\n",
       "      <th>dog !</th>\n",
       "      <th>fox</th>\n",
       "      <th>fox .</th>\n",
       "      <th>jump</th>\n",
       "      <th>jump lazy</th>\n",
       "      <th>lazy</th>\n",
       "      <th>lazy dog</th>\n",
       "      <th>quick</th>\n",
       "      <th>quick brown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      !  .  brown  brown fox  dog  dog !  fox  fox .  jump  jump lazy  lazy  \\\n",
       "Doc0  0  1      1          1    0      0    1      1     0          0     0   \n",
       "Doc1  1  0      0          0    1      1    0      0     1          1     1   \n",
       "\n",
       "      lazy dog  quick  quick brown  \n",
       "Doc0         0      1            1  \n",
       "Doc1         1      0            0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer with custom preprocessor and tokenizer,\n",
    "# set to remove stop words and extract bigrams\n",
    "custom_vec = CountVectorizer(preprocessor=my_preprocessor,\n",
    "                             tokenizer=my_tokenizer,\n",
    "                             ngram_range=(1,2),\n",
    "                             stop_words='english')\n",
    "cwm = custom_vec.fit_transform(corpora)\n",
    "tokens = custom_vec.get_feature_names()\n",
    "wm2df(cwm, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom analyzer\n",
    "Customizing a vectorizer with a user define callable class as analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jump</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      !  .  brown  dog  fox  jump  lazy  over  quick  the\n",
       "Doc0  0  1      1    0    1     0     0     0      1    1\n",
       "Doc1  1  0      0    1    0     1     1     1      0    1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom analyzer class\n",
    "class MyAnalyzer(object):\n",
    "    \n",
    "    # load spaCy's english model and define the tokenizer/lemmatizer\n",
    "    def __init__(self):\n",
    "        spacy.load('en')\n",
    "        self.lemmatizer_ = spacy.lang.en.English()\n",
    "        \n",
    "    # allow the class instance to be called just like\n",
    "    # just like a function and applies the preprocessing and\n",
    "    # tokenize the document\n",
    "    def __call__(self, doc):\n",
    "        doc_clean = unescape(doc).lower()\n",
    "        tokens = self.lemmatizer_(doc_clean)\n",
    "        return([token.lemma_ for token in tokens])\n",
    "    \n",
    "analyzer = MyAnalyzer()\n",
    "custom_vec = CountVectorizer(analyzer=analyzer,\n",
    "                             ngram_range=(1,2),\n",
    "                             stop_words='english')\n",
    "cwm = custom_vec.fit_transform(corpora)\n",
    "tokens = custom_vec.get_feature_names()\n",
    "wm2df(cwm, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified vectorizer class\n",
    "Create a modfified vectorizer by creating a new class which inherits from the CountVectorizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>.</th>\n",
       "      <th>brown</th>\n",
       "      <th>brown fox</th>\n",
       "      <th>dog</th>\n",
       "      <th>dog !</th>\n",
       "      <th>fox</th>\n",
       "      <th>fox .</th>\n",
       "      <th>jump</th>\n",
       "      <th>jump lazy</th>\n",
       "      <th>lazy</th>\n",
       "      <th>lazy dog</th>\n",
       "      <th>quick</th>\n",
       "      <th>quick brown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      !  .  brown  brown fox  dog  dog !  fox  fox .  jump  jump lazy  lazy  \\\n",
       "Doc0  0  1      1          1    0      0    1      1     0          0     0   \n",
       "Doc1  1  0      0          0    1      1    0      0     1          1     1   \n",
       "\n",
       "      lazy dog  quick  quick brown  \n",
       "Doc0         0      1            1  \n",
       "Doc1         1      0            0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defines a custom vectorizer class\n",
    "class CustomVectorizer(CountVectorizer): \n",
    "    \n",
    "    # overwrite the build_analyzer method, allowing one to\n",
    "    # create a custom analyzer for the vectorizer\n",
    "    def build_analyzer(self):\n",
    "        \n",
    "        # load stop words using CountVectorizer's built in method\n",
    "        stop_words = self.get_stop_words()\n",
    "        \n",
    "        # create the analyzer that will be returned by this method\n",
    "        def analyser(doc):\n",
    "            \n",
    "            # load spaCy's model for english language\n",
    "            spacy.load('en')\n",
    "            \n",
    "            # instantiate a spaCy tokenizer\n",
    "            lemmatizer = spacy.lang.en.English()\n",
    "            \n",
    "            # apply the preprocessing and tokenzation steps\n",
    "            doc_clean = unescape(doc).lower()\n",
    "            tokens = lemmatizer(doc_clean)\n",
    "            lemmatized_tokens = [token.lemma_ for token in tokens]\n",
    "            \n",
    "            # use CountVectorizer's _word_ngrams built in method\n",
    "            # to remove stop words and extract n-grams\n",
    "            return(self._word_ngrams(lemmatized_tokens, stop_words))\n",
    "        return(analyser)\n",
    "    \n",
    "\n",
    "custom_vec = CustomVectorizer(ngram_range=(1,2),\n",
    "                              stop_words='english')\n",
    "cwm = custom_vec.fit_transform(corpora)\n",
    "wm2df(cwm, custom_vec.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
